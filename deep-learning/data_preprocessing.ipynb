{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd026848223f25c0528451d7ef97ec918be2ab27e3833c08cd7061af0e1e902404a",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "26848223f25c0528451d7ef97ec918be2ab27e3833c08cd7061af0e1e902404a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data preprocessing for LSTM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\git_space\\COVID-19-prediction-project\\data\\kr_regional_daily.csv')\n",
    "df = df.drop(['date', 'region', 'death', 'released'], axis=1)\n",
    "\n",
    "df_list = df['confirmed'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seoul = []\n",
    "Pusan = []\n",
    "Daegu = []\n",
    "Incheon = []\n",
    "Gwangju = []\n",
    "Daejeon = []\n",
    "Ulsan = []\n",
    "Sejong = []\n",
    "Gyeonggi = []\n",
    "Gangwon = []\n",
    "Chungbuk = []\n",
    "Chungnam = []\n",
    "Jeonbuk = []\n",
    "Jeonnam = []\n",
    "Gyeongbuk = []\n",
    "Gyeongnam = []\n",
    "Jeju = []\n",
    "Overseas = []\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "  if i % 18 == 0:\n",
    "    Seoul.append(df_list[i])\n",
    "\n",
    "  elif i % 18 == 1:\n",
    "    Pusan.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 2:\n",
    "    Daegu.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 3:\n",
    "    Incheon.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 4:\n",
    "    Gwangju.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 5:\n",
    "    Daejeon.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 6:\n",
    "    Ulsan.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 7:\n",
    "    Sejong.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 8:\n",
    "    Gyeonggi.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 9:\n",
    "    Gangwon.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 10:\n",
    "    Chungbuk.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 11:\n",
    "    Chungnam.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 12:\n",
    "    Jeonbuk.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 13:\n",
    "    Jeonnam.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 14:\n",
    "    Gyeongbuk.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 15:\n",
    "    Gyeongnam.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 16:\n",
    "    Jeju.append(df_list[i])\n",
    "    \n",
    "  elif i % 18 == 17:\n",
    "    Overseas.append(df_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seoul = pd.DataFrame(Seoul, columns=['confirmed'])\n",
    "Pusan = pd.DataFrame(Pusan, columns=['confirmed'])\n",
    "Daegu = pd.DataFrame(Daegu, columns=['confirmed'])\n",
    "Incheon = pd.DataFrame(Incheon, columns=['confirmed'])\n",
    "Gwangju = pd.DataFrame(Gwangju, columns=['confirmed'])\n",
    "Daejeon = pd.DataFrame(Daejeon, columns=['confirmed'])\n",
    "Ulsan = pd.DataFrame(Ulsan, columns=['confirmed'])\n",
    "Sejong = pd.DataFrame(Sejong, columns=['confirmed'])\n",
    "Gyeonggi = pd.DataFrame(Gyeonggi, columns=['confirmed'])\n",
    "Gangwon = pd.DataFrame(Gangwon, columns=['confirmed'])\n",
    "Chungbuk = pd.DataFrame(Chungbuk, columns=['confirmed'])\n",
    "Chungnam = pd.DataFrame(Chungnam, columns=['confirmed'])\n",
    "Jeonbuk = pd.DataFrame(Jeonbuk, columns=['confirmed'])\n",
    "Jeonnam = pd.DataFrame(Jeonnam, columns=['confirmed'])\n",
    "Gyeongbuk = pd.DataFrame(Gyeongbuk, columns=['confirmed'])\n",
    "Gyeongnam = pd.DataFrame(Gyeongnam, columns=['confirmed'])\n",
    "Jeju = pd.DataFrame(Jeju, columns=['confirmed'])\n",
    "Overseas = pd.DataFrame(Overseas, columns=['confirmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_diff(dataframe):\n",
    "    \n",
    "    df_list = dataframe['confirmed'].tolist()\n",
    "    diff = []\n",
    "\n",
    "    for i in range(len(df_list)):\n",
    "        if i != 0:\n",
    "            diff.append(df_list[i] - df_list[i - 1])\n",
    "\n",
    "    sub = [1]\n",
    "    diff = sub + diff\n",
    "\n",
    "    diff = pd.DataFrame(diff, columns=['confirmed'])\n",
    "\n",
    "    return diff\n",
    "\n",
    "\n",
    "def diff_level(dataframe, level):\n",
    "\n",
    "    model = dataframe\n",
    "\n",
    "    for i in range(level):\n",
    "        model = make_diff(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seoul = diff_level(Seoul, 1)\n",
    "Pusan = diff_level(Pusan, 1)\n",
    "Daegu = diff_level(Daegu, 1)\n",
    "Incheon = diff_level(Incheon, 1)\n",
    "Gwangju = diff_level(Gwangju, 1)\n",
    "Daejeon = diff_level(Daejeon, 1)\n",
    "Ulsan = diff_level(Ulsan, 1)\n",
    "Sejong = diff_level(Sejong, 1)\n",
    "Gyeonggi = diff_level(Gyeonggi, 1)\n",
    "Gangwon = diff_level(Gangwon, 1)\n",
    "Chungbuk = diff_level(Chungbuk, 1)\n",
    "Chungnam = diff_level(Chungnam, 1)\n",
    "Jeonbuk = diff_level(Jeonbuk, 1)\n",
    "Jeonnam = diff_level(Jeonnam, 1)\n",
    "Gyeongbuk = diff_level(Gyeongbuk, 1)\n",
    "Gyeongnam = diff_level(Gyeongnam, 1)\n",
    "Jeju = diff_level(Jeju, 1)\n",
    "Overseas = diff_level(Overseas, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(feature, target):\n",
    "    dataset = pd.concat([feature, target], axis=1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     confirmed  confirmed\n",
       "0            1          1\n",
       "1            0          0\n",
       "2            0          0\n",
       "3            0          8\n",
       "4            0          0\n",
       "..         ...        ...\n",
       "461          1         15\n",
       "462         14         15\n",
       "463         14         16\n",
       "464          9         22\n",
       "465          8         18\n",
       "\n",
       "[466 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>confirmed</th>\n      <th>confirmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>461</th>\n      <td>1</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>462</th>\n      <td>14</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>463</th>\n      <td>14</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>464</th>\n      <td>9</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>465</th>\n      <td>8</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n<p>466 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "make_dataset(Sejong, Pusan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features and target\n",
    "X_value = pd.DataFrame(dataset.iloc[:, 0]) # feature\n",
    "y_value = pd.DataFrame(dataset.iloc[:, 1]) # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized the data\n",
    "X_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_scaler.fit(X_value)\n",
    "y_scaler.fit(y_value)\n",
    "\n",
    "X_scale_dataset = X_scaler.fit_transform(X_value)\n",
    "y_scale_dataset = y_scaler.fit_transform(y_value)\n",
    "\n",
    "dump(X_scaler, open('X_scaler.pkl', 'wb'))\n",
    "dump(y_scaler, open('y_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "'''\n",
    "Set the data input steps and output steps, \n",
    "we use 30 days data to predict 1 day price here, \n",
    "reshape it to (None, input_step, number of features) used for LSTM input\n",
    "'''\n",
    "\n",
    "n_steps_in = 30\n",
    "n_features = X_value.shape[1]\n",
    "n_steps_out = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X/y dataset\n",
    "def get_X_y(X_data, y_data):\n",
    "    X = list()\n",
    "    y = list()\n",
    "    yc = list()\n",
    "\n",
    "    length = len(X_data)\n",
    "    for i in range(0, length, 1):\n",
    "        X_value = X_data[i: i + n_steps_in][:, :]\n",
    "        y_value = y_data[i + n_steps_in: i + (n_steps_in + n_steps_out)][:, 0]\n",
    "        yc_value = y_data[i: i + n_steps_in][:, :]\n",
    "        if len(X_value) == 30 and len(y_value) == 1:\n",
    "            X.append(X_value)\n",
    "            y.append(y_value)\n",
    "            yc.append(yc_value)\n",
    "\n",
    "    return np.array(X), np.array(y), np.array(yc)\n",
    "\n",
    "# get the train test predict index\n",
    "def predict_index(dataset, X_train, n_steps_in, n_steps_out):\n",
    "\n",
    "    # get the predict data (remove the in_steps days)\n",
    "    train_predict_index = dataset.iloc[n_steps_in : X_train.shape[0] + n_steps_in + n_steps_out - 1, :].index\n",
    "    test_predict_index = dataset.iloc[X_train.shape[0] + n_steps_in:, :].index\n",
    "\n",
    "    return train_predict_index, test_predict_index\n",
    "\n",
    "# Split train/test dataset\n",
    "def split_train_test(data):\n",
    "    train_size = round(len(X) * 0.7)\n",
    "    data_train = data[0:train_size]\n",
    "    data_test = data[train_size:]\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and check shape\n",
    "X, y, yc = get_X_y(X_scale_dataset, y_scale_dataset)\n",
    "X_train, X_test, = split_train_test(X)\n",
    "y_train, y_test, = split_train_test(y)\n",
    "yc_train, yc_test, = split_train_test(yc)\n",
    "index_train, index_test, = predict_index(dataset, X_train, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% --------------------------------------- Save dataset -----------------------------------------------------------------\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_c_train shape: ', yc_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)\n",
    "print('y_c_test shape: ', yc_test.shape)\n",
    "print('index_train shape:', index_train.shape)\n",
    "print('index_test shape:', index_test.shape)\n",
    "\n",
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_test.npy\", y_test)\n",
    "np.save(\"yc_train.npy\", yc_train)\n",
    "np.save(\"yc_test.npy\", yc_test)\n",
    "np.save('index_train.npy', index_train)\n",
    "np.save('index_test.npy', index_test)"
   ]
  }
 ]
}